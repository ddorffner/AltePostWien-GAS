{
  "65": {
    "inputs": {
      "guidance": 2.9000000000000004,
      "conditioning": [
        "67",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "66": {
    "inputs": {
      "text": "dof, depth of field, blurry, overexposed, noise",
      "clip": [
        "68",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "VL Negative Prompt Gen"
    }
  },
  "67": {
    "inputs": {
      "text": [
        "69",
        0
      ],
      "clip": [
        "68",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "68": {
    "inputs": {
      "clip_name1": "clip_l.safetensors",
      "clip_name2": "t5xxl_fp8_e4m3fn.safetensors",
      "type": "flux",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "69": {
    "inputs": {
      "string_a": [
        "70",
        2
      ],
      "string_b": [
        "74",
        0
      ],
      "delimiter": ""
    },
    "class_type": "StringConcatenate",
    "_meta": {
      "title": "Concatenate"
    }
  },
  "70": {
    "inputs": {
      "text_input": "",
      "task": "more_detailed_caption",
      "fill_mask": true,
      "keep_model_loaded": false,
      "max_new_tokens": 1024,
      "num_beams": 3,
      "do_sample": true,
      "output_mask_select": "",
      "seed": 229181029129501,
      "image": [
        "156",
        0
      ],
      "florence2_model": [
        "71",
        0
      ]
    },
    "class_type": "Florence2Run",
    "_meta": {
      "title": "Florence2Run"
    }
  },
  "71": {
    "inputs": {
      "model": "gokaygokay/Florence-2-SD3-Captioner",
      "precision": "fp16",
      "attention": "sdpa",
      "convert_to_safetensors": false
    },
    "class_type": "DownloadAndLoadFlorence2Model",
    "_meta": {
      "title": "DownloadAndLoadFlorence2Model"
    }
  },
  "74": {
    "inputs": {
      "value": "scene arranged on a ceiling, perspective looking straight. symmetric composition, 4k, uhd, sharp focus, detailed\", \"crisp\" \"all in sharp focus, everything in focus"
    },
    "class_type": "PrimitiveString",
    "_meta": {
      "title": "VL POST PROMPT GEN"
    }
  },
  "75": {
    "inputs": {
      "guidance": 3,
      "conditioning": [
        "66",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "77": {
    "inputs": {
      "size": 1536,
      "method": "NEAREST",
      "image": [
        "235",
        0
      ]
    },
    "class_type": "ResizeLongestToNode",
    "_meta": {
      "title": "VL Depth Input Resize Longest"
    }
  },
  "101": {
    "inputs": {
      "image": [
        "77",
        0
      ]
    },
    "class_type": "GetImageSize+",
    "_meta": {
      "title": "ðŸ”§ Get Image Size"
    }
  },
  "106": {
    "inputs": {
      "clip_name": "sigclip_vision_patch14_384.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "108": {
    "inputs": {
      "downsampling_factor": 2,
      "downsampling_function": "bilinear",
      "mode": "center crop (square)",
      "weight": 0.45000000000000007,
      "autocrop_margin": 0.1,
      "conditioning": [
        "127",
        0
      ],
      "style_model": [
        "115",
        0
      ],
      "clip_vision": [
        "106",
        0
      ],
      "image": [
        "156",
        0
      ]
    },
    "class_type": "ReduxAdvanced",
    "_meta": {
      "title": "VL Redux"
    }
  },
  "109": {
    "inputs": {
      "samples": [
        "113",
        0
      ],
      "vae": [
        "110",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "110": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "111": {
    "inputs": {
      "sampler_name": "euler"
    },
    "class_type": "KSamplerSelect",
    "_meta": {
      "title": "KSamplerSelect"
    }
  },
  "112": {
    "inputs": {
      "scheduler": "ddim_uniform",
      "steps": 25,
      "denoise": 1,
      "model": [
        "169",
        0
      ]
    },
    "class_type": "BasicScheduler",
    "_meta": {
      "title": "VL Scheduler"
    }
  },
  "113": {
    "inputs": {
      "noise": [
        "117",
        0
      ],
      "guider": [
        "124",
        0
      ],
      "sampler": [
        "111",
        0
      ],
      "sigmas": [
        "112",
        0
      ],
      "latent_image": [
        "116",
        0
      ]
    },
    "class_type": "SamplerCustomAdvanced",
    "_meta": {
      "title": "SamplerCustomAdvanced"
    }
  },
  "115": {
    "inputs": {
      "style_model_name": "flux1-redux-dev.safetensors"
    },
    "class_type": "StyleModelLoader",
    "_meta": {
      "title": "Load Style Model"
    }
  },
  "116": {
    "inputs": {
      "width": [
        "101",
        0
      ],
      "height": [
        "101",
        1
      ],
      "batch_size": 1
    },
    "class_type": "EmptySD3LatentImage",
    "_meta": {
      "title": "EmptySD3LatentImage"
    }
  },
  "117": {
    "inputs": {
      "noise_seed": 123456
    },
    "class_type": "RandomNoise",
    "_meta": {
      "title": "VL Seed Gen"
    }
  },
  "123": {
    "inputs": {
      "unet_name": "flux1-dev-fp8.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "VL Model Gen"
    }
  },
  "124": {
    "inputs": {
      "model": [
        "169",
        0
      ],
      "conditioning": [
        "143",
        0
      ]
    },
    "class_type": "BasicGuider",
    "_meta": {
      "title": "BasicGuider"
    }
  },
  "125": {
    "inputs": {
      "type": "depth",
      "control_net": [
        "128",
        0
      ]
    },
    "class_type": "SetShakkerLabsUnionControlNetType",
    "_meta": {
      "title": "Set Shakker Labs Union ControlNet Type"
    }
  },
  "127": {
    "inputs": {
      "strength": 0.4000000000000001,
      "start_percent": 0,
      "end_percent": 0.30000000000000004,
      "positive": [
        "65",
        0
      ],
      "negative": [
        "75",
        0
      ],
      "control_net": [
        "125",
        0
      ],
      "image": [
        "77",
        0
      ],
      "vae": [
        "110",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "VL ControlNet Depth 1"
    }
  },
  "128": {
    "inputs": {
      "control_net_name": "controlnet-union_shakker.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "141": {
    "inputs": {
      "type": "depth",
      "control_net": [
        "142",
        0
      ]
    },
    "class_type": "SetShakkerLabsUnionControlNetType",
    "_meta": {
      "title": "Set Shakker Labs Union ControlNet Type"
    }
  },
  "142": {
    "inputs": {
      "control_net_name": "controlnet-union_shakker.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "143": {
    "inputs": {
      "strength": 0.44000000000000006,
      "start_percent": 0,
      "end_percent": 0.5000000000000001,
      "positive": [
        "108",
        0
      ],
      "negative": [
        "75",
        0
      ],
      "control_net": [
        "125",
        0
      ],
      "image": [
        "77",
        0
      ],
      "vae": [
        "110",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "VL ControlNet Depth 2"
    }
  },
  "144": {
    "inputs": {
      "low_threshold": 8,
      "high_threshold": 30,
      "resolution": 512,
      "image": [
        "77",
        0
      ]
    },
    "class_type": "CannyEdgePreprocessor",
    "_meta": {
      "title": "Canny Edge"
    }
  },
  "147": {
    "inputs": {
      "type": "canny",
      "control_net": [
        "128",
        0
      ]
    },
    "class_type": "SetShakkerLabsUnionControlNetType",
    "_meta": {
      "title": "Set Shakker Labs Union ControlNet Type"
    }
  },
  "156": {
    "inputs": {
      "size": 1024,
      "method": "NEAREST",
      "image": [
        "236",
        0
      ]
    },
    "class_type": "ResizeLongestToNode",
    "_meta": {
      "title": "VL Input Image Resize Longest"
    }
  },
  "164": {
    "inputs": {
      "ipadapter": "ip-adapter.bin",
      "clip_vision": "google/siglip-so400m-patch14-384",
      "provider": "cuda"
    },
    "class_type": "IPAdapterFluxLoader",
    "_meta": {
      "title": "Load IPAdapter Flux Model"
    }
  },
  "165": {
    "inputs": {
      "weight": 0.7500000000000001,
      "start_percent": 0,
      "end_percent": 0.9000000000000002,
      "model": [
        "123",
        0
      ],
      "ipadapter_flux": [
        "164",
        0
      ],
      "image": [
        "156",
        0
      ]
    },
    "class_type": "ApplyIPAdapterFlux",
    "_meta": {
      "title": "VL IPAdapter"
    }
  },
  "169": {
    "inputs": {
      "lora_name": "FLUX-dev-lora-AntiBlur.safetensors",
      "strength_model": 0.9000000000000001,
      "model": [
        "165",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "VL Lora 1"
    }
  },
  "179": {
    "inputs": {
      "use_tiled_vae": true,
      "encoder_tile_size": [
        "185",
        0
      ],
      "decoder_tile_size": [
        "185",
        0
      ],
      "encoder_dtype": "auto",
      "SUPIR_VAE": [
        "186",
        1
      ],
      "image": [
        "195",
        0
      ]
    },
    "class_type": "SUPIR_first_stage",
    "_meta": {
      "title": "SUPIR First Stage (Denoiser)"
    }
  },
  "182": {
    "inputs": {
      "use_tiled_vae": true,
      "decoder_tile_size": [
        "185",
        0
      ],
      "SUPIR_VAE": [
        "186",
        1
      ],
      "latents": [
        "197",
        0
      ]
    },
    "class_type": "SUPIR_decode",
    "_meta": {
      "title": "SUPIR Decode"
    }
  },
  "183": {
    "inputs": {
      "seed": -1
    },
    "class_type": "Seed (rgthree)",
    "_meta": {
      "title": "Seed (rgthree)"
    }
  },
  "184": {
    "inputs": {
      "value": 512
    },
    "class_type": "ImpactInt",
    "_meta": {
      "title": "Tile Stride"
    }
  },
  "185": {
    "inputs": {
      "value": 1024
    },
    "class_type": "ImpactInt",
    "_meta": {
      "title": "Tile Size"
    }
  },
  "186": {
    "inputs": {
      "supir_model": "SUPIR-v0Q_fp16.safetensors",
      "fp8_unet": false,
      "diffusion_dtype": "auto",
      "high_vram": true,
      "model": [
        "187",
        0
      ],
      "clip": [
        "187",
        1
      ],
      "vae": [
        "187",
        2
      ]
    },
    "class_type": "SUPIR_model_loader_v2",
    "_meta": {
      "title": "SUPIR Model Loader (v2)"
    }
  },
  "187": {
    "inputs": {
      "ckpt_name": "Juggernaut_RunDiffusionPhoto2_Lightning_4Steps.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint Lightning"
    }
  },
  "189": {
    "inputs": {
      "use_tiled_vae": true,
      "encoder_tile_size": [
        "185",
        0
      ],
      "encoder_dtype": "auto",
      "SUPIR_VAE": [
        "179",
        0
      ],
      "image": [
        "179",
        1
      ]
    },
    "class_type": "SUPIR_encode",
    "_meta": {
      "title": "SUPIR Encode"
    }
  },
  "193": {
    "inputs": {
      "text": "best quality, 8K, smooth details",
      "clip": [
        "187",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "VL Upscale Ultimate Prompt"
    }
  },
  "194": {
    "inputs": {
      "text": "text, watermark, cartoon",
      "clip": [
        "187",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "195": {
    "inputs": {
      "width": 3600,
      "height": 1032,
      "interpolation": "lanczos",
      "method": "stretch",
      "condition": "always",
      "multiple_of": 8,
      "image": [
        "109",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "VL Upscale Resize 1"
    }
  },
  "197": {
    "inputs": {
      "seed": [
        "183",
        0
      ],
      "steps": 30,
      "cfg_scale_start": 0.9000000000000001,
      "cfg_scale_end": 1.0000000000000002,
      "EDM_s_churn": 3,
      "s_noise": 1.0030000000000001,
      "DPMPP_eta": 1,
      "control_scale_start": 1,
      "control_scale_end": 0.9,
      "restore_cfg": 1.0000000000000002,
      "keep_model_loaded": false,
      "sampler": "RestoreDPMPP2MSampler",
      "sampler_tile_size": [
        "185",
        0
      ],
      "sampler_tile_stride": [
        "184",
        0
      ],
      "SUPIR_model": [
        "186",
        0
      ],
      "latents": [
        "189",
        0
      ],
      "positive": [
        "204",
        0
      ],
      "negative": [
        "204",
        1
      ]
    },
    "class_type": "SUPIR_sample",
    "_meta": {
      "title": "VL SUPIR Sampler"
    }
  },
  "199": {
    "inputs": {
      "model_name": "RealESRGAN_x4plus.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "200": {
    "inputs": {
      "upscale_by": 2.0000000000000004,
      "seed": [
        "183",
        0
      ],
      "steps": 4,
      "cfg": 2,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.15000000000000002,
      "mode_type": "None",
      "tile_width": 1024,
      "tile_height": 1024,
      "mask_blur": 16,
      "tile_padding": 32,
      "seam_fix_mode": "Band Pass",
      "seam_fix_denoise": 1,
      "seam_fix_width": 64,
      "seam_fix_mask_blur": 16,
      "seam_fix_padding": 16,
      "force_uniform_tiles": "enable",
      "tiled_decode": false,
      "image": [
        "202",
        0
      ],
      "model": [
        "187",
        0
      ],
      "positive": [
        "193",
        0
      ],
      "negative": [
        "194",
        0
      ],
      "vae": [
        "187",
        2
      ],
      "upscale_model": [
        "199",
        0
      ]
    },
    "class_type": "UltimateSDUpscale",
    "_meta": {
      "title": "Ultimate SD Upscale"
    }
  },
  "201": {
    "inputs": {
      "model": "depth_anything_v2_vits_fp16.safetensors"
    },
    "class_type": "DownloadAndLoadDepthAnythingV2Model",
    "_meta": {
      "title": "DownloadAndLoadDepthAnythingV2Model"
    }
  },
  "202": {
    "inputs": {
      "method": "mkl",
      "strength": 0.6,
      "image_ref": [
        "195",
        0
      ],
      "image_target": [
        "182",
        0
      ]
    },
    "class_type": "ColorMatch",
    "_meta": {
      "title": "Color Match"
    }
  },
  "204": {
    "inputs": {
      "positive_prompt": "high quality, detailed",
      "negative_prompt": "blurry",
      "SUPIR_model": [
        "186",
        0
      ],
      "latents": [
        "179",
        2
      ]
    },
    "class_type": "SUPIR_conditioner",
    "_meta": {
      "title": "SUPIR Conditioner"
    }
  },
  "206": {
    "inputs": {
      "da_model": [
        "201",
        0
      ],
      "images": [
        "213",
        0
      ]
    },
    "class_type": "DepthAnything_V2",
    "_meta": {
      "title": "Depth Anything V2"
    }
  },
  "209": {
    "inputs": {
      "width": 9600,
      "height": 2752,
      "interpolation": "lanczos",
      "method": "stretch",
      "condition": "always",
      "multiple_of": 8,
      "image": [
        "200",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "VL Upscale Resize Final"
    }
  },
  "213": {
    "inputs": {
      "width": 2400,
      "height": 688,
      "upscale_method": "nearest-exact",
      "keep_proportion": "stretch",
      "pad_color": "0, 0, 0",
      "crop_position": "center",
      "divisible_by": 1,
      "device": "gpu",
      "image": [
        "202",
        0
      ]
    },
    "class_type": "ImageResizeKJv2",
    "_meta": {
      "title": "VL Depth Output Size Gen"
    }
  },
  "215": {
    "inputs": {
      "size": 512,
      "method": "NEAREST",
      "image": [
        "109",
        0
      ]
    },
    "class_type": "ResizeLongestToNode",
    "_meta": {
      "title": "Resize Longest To"
    }
  },
  "225": {
    "inputs": {
      "value": "DGN_Medium"
    },
    "class_type": "PrimitiveString",
    "_meta": {
      "title": "VL Output Path Medium"
    }
  },
  "226": {
    "inputs": {
      "value": "DGN_Color"
    },
    "class_type": "PrimitiveString",
    "_meta": {
      "title": "VL Output Path Color"
    }
  },
  "227": {
    "inputs": {
      "value": "DGN_Thumb"
    },
    "class_type": "PrimitiveString",
    "_meta": {
      "title": "VL Output Path Thumb"
    }
  },
  "228": {
    "inputs": {
      "value": "DGN_Depth"
    },
    "class_type": "PrimitiveString",
    "_meta": {
      "title": "VL Output Path Depth"
    }
  },
  "231": {
    "inputs": {
      "width": 4800,
      "height": 1376,
      "upscale_method": "nearest-exact",
      "keep_proportion": "stretch",
      "pad_color": "0, 0, 0",
      "crop_position": "center",
      "divisible_by": 1,
      "device": "gpu",
      "image": [
        "206",
        0
      ]
    },
    "class_type": "ImageResizeKJv2",
    "_meta": {
      "title": "VL Depth Output Size Final"
    }
  },
  "235": {
    "inputs": {
      "image": "C:\\ASSETS\\DepthMap\\DGN\\DGN.jpg"
    },
    "class_type": "LoadImageFromPath",
    "_meta": {
      "title": "VL Depth Input Image"
    }
  },
  "236": {
    "inputs": {
      "image": "..."
    },
    "class_type": "LoadImageFromPath",
    "_meta": {
      "title": "VL Input Image"
    }
  },
  "241": {
    "inputs": {
      "filepath": [
        "227",
        0
      ],
      "png_16bit": false,
      "image": [
        "215",
        0
      ]
    },
    "class_type": "SaveImageAndPromptExact",
    "_meta": {
      "title": "Save Image And Prompt (exact)"
    }
  },
  "242": {
    "inputs": {
      "filepath": [
        "226",
        0
      ],
      "png_16bit": false,
      "image": [
        "209",
        0
      ]
    },
    "class_type": "SaveImageAndPromptExact",
    "_meta": {
      "title": "Save Image And Prompt (exact)"
    }
  },
  "243": {
    "inputs": {
      "filepath": [
        "225",
        0
      ],
      "png_16bit": false,
      "image": [
        "202",
        0
      ]
    },
    "class_type": "SaveImageAndPromptExact",
    "_meta": {
      "title": "Save Image And Prompt (exact)"
    }
  },
  "244": {
    "inputs": {
      "filepath": [
        "228",
        0
      ],
      "tonemap": "sRGB",
      "start_frame": 1001,
      "overwrite": true,
      "save_workflow": "none",
      "images": [
        "231",
        0
      ]
    },
    "class_type": "SaveEXRFrames",
    "_meta": {
      "title": "Save EXR Frames"
    }
  }
}